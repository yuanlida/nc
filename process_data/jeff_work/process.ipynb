{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"/Users/macos/Desktop/Edison-ai/data/ner/charbased/oesm18nat/national_M2018_dl.xlsx\")\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1379 entries, 0 to 1378\n",
      "Data columns (total 20 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   OCC_CODE   1379 non-null   object \n",
      " 1   OCC_TITLE  1379 non-null   object \n",
      " 2   OCC_GROUP  1379 non-null   object \n",
      " 3   TOT_EMP    1379 non-null   int64  \n",
      " 4   EMP_PRSE   1379 non-null   float64\n",
      " 5   H_MEAN     1379 non-null   object \n",
      " 6   A_MEAN     1379 non-null   object \n",
      " 7   MEAN_PRSE  1379 non-null   float64\n",
      " 8   H_PCT10    1379 non-null   object \n",
      " 9   H_PCT25    1379 non-null   object \n",
      " 10  H_MEDIAN   1379 non-null   object \n",
      " 11  H_PCT75    1379 non-null   object \n",
      " 12  H_PCT90    1379 non-null   object \n",
      " 13  A_PCT10    1379 non-null   object \n",
      " 14  A_PCT25    1379 non-null   object \n",
      " 15  A_MEDIAN   1379 non-null   object \n",
      " 16  A_PCT75    1379 non-null   object \n",
      " 17  A_PCT90    1379 non-null   object \n",
      " 18  ANNUAL     82 non-null     object \n",
      " 19  HOURLY     6 non-null      object \n",
      "dtypes: float64(2), int64(1), object(17)\n",
      "memory usage: 215.6+ KB\n",
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df.info()\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0                             All Occupations\n",
      "1                      Management Occupations\n",
      "2                              Top Executives\n",
      "3                            Chief Executives\n",
      "4                            Chief Executives\n",
      "                        ...                  \n",
      "1374               Mine Shuttle Car Operators\n",
      "1375        Tank Car, Truck, and Ship Loaders\n",
      "1376        Tank Car, Truck, and Ship Loaders\n",
      "1377    Miscellaneous Material Moving Workers\n",
      "1378       Material Moving Workers, All Other\n",
      "Name: OCC_TITLE, Length: 1379, dtype: object\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "occ = df['OCC_TITLE']\n",
    "print(occ)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import inflect\n",
    "inflect = inflect.engine()\n",
    "\n",
    "tit_occ = \"/Users/macos/thunder/ner-tf/cls_data/tit_occ.txt\"\n",
    "\n",
    "lines_seen = set()\n",
    "with open (tit_occ, 'w') as w:\n",
    "    # def write_out(line):\n",
    "    for num,line in enumerate(occ):\n",
    "        if num>3:\n",
    "        # tit = \"\"\n",
    "            if line not in lines_seen:# and line != '\\n':\n",
    "                lines_seen.add(line)\n",
    "                if inflect.singular_noun(line)==False:\n",
    "                    # line1 = line[:-1]\n",
    "                    w.writelines(line)\n",
    "                    w.writelines('\\n')\n",
    "                else:\n",
    "                    line = inflect.singular_noun(line)\n",
    "                    w.writelines(line)\n",
    "                    w.writelines('\\n')\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## extract OESM18 Occupation data\n",
    "lines_seen = set()\n",
    "with open (tit_occ, 'w') as w:\n",
    "    def write_out(line):\n",
    "            if line not in lines_seen:# and line != '\\n':\n",
    "                lines_seen.add(line)\n",
    "                if inflect.singular_noun(line)==False:\n",
    "                    # line1 = line[:-1]\n",
    "                    w.writelines(line)\n",
    "                    w.writelines('\\n')\n",
    "                else:\n",
    "                    line = inflect.singular_noun(line)\n",
    "                    w.writelines(line)\n",
    "                    w.writelines('\\n')\n",
    "    for num,line in enumerate(occ):\n",
    "        tit = \"\"\n",
    "        if num>3:\n",
    "            doc = line.split()\n",
    "            if 'and' in doc:\n",
    "                n = doc.index('and')\n",
    "                # print(n)\n",
    "                tit = ''\n",
    "                for i,word in enumerate(doc):\n",
    "                    if word.endswith(','): #or doc[i+1]!='and':\n",
    "                        tit = word[:-1] + ' ' + doc[-1]\n",
    "                        # print('1' + tit)\n",
    "                        write_out(tit)\n",
    "                        tit = ''\n",
    "                    elif word==('and') and (doc[i-1].endswith(',')==False):\n",
    "                        tit+=doc[-1]\n",
    "                        # print('2' + tit)\n",
    "                        write_out(tit)\n",
    "                        tit = ''\n",
    "                        continue\n",
    "                    elif word==('and') and (doc[i-1].endswith(',')==True):\n",
    "                        tit+=doc[-1]\n",
    "                        # print('2' + tit)\n",
    "                        write_out(tit)\n",
    "                        tit = ''\n",
    "                        continue\n",
    "                    elif word == doc[-1]:\n",
    "                        tit+= word\n",
    "                        # print('3' + tit)\n",
    "                        write_out(tit)\n",
    "                        continue\n",
    "                    else:\n",
    "                        tit+= word + ' '\n",
    "                        continue\n",
    "            else:\n",
    "                write_out(line) \n",
    "                    \n",
    "#manually remove excepts, others\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "/Users/macos/thunder/ner-tf/cls_data/tit_occ.txt\n",
      "/Users/macos/thunder/ner-tf/cls_data/title.txt\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## CONCAT\n",
    "file1 = \"/Users/macos/thunder/ner-tf/cls_data/title.txt\"\n",
    "file2 = \"/Users/macos/thunder/ner-tf/cls_data/tit_occ.txt\"\n",
    "combined = \"/Users/macos/thunder/ner-tf/cls_data/tit.txt\"\n",
    "\n",
    "import os, glob\n",
    "files = glob.glob('/Users/macos/thunder/ner-tf/cls_data/tit*')\n",
    "\n",
    "all_lines = []\n",
    "for f in files:\n",
    "    print(f)\n",
    "    with open(f,'r') as fi:\n",
    "        all_lines += fi.readlines()\n",
    "all_lines = set(all_lines)\n",
    "\n",
    "with open(combined,'w') as fo:\n",
    "    fo.write(\"\".join(all_lines))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## split us street names without designation\n",
    "str_file = '/Users/macos/thunder/ner-tf/cls_data/extra/street_name.txt'\n",
    "str_only = '/Users/macos/thunder/ner-tf/jeff_work/place_list/str_only.txt'\n",
    "\n",
    "str_list = []\n",
    "with open (str_file, 'r') as r:\n",
    "    for line in r.readlines():\n",
    "        str_list.append(' '.join(line.split(' ')[:-1]).title())\n",
    "        # remove last word\n",
    "        \n",
    "with open (str_only, 'w') as w:\n",
    "    for street in str_list:\n",
    "        w.writelines(street)\n",
    "        w.writelines('\\n')\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "start\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Extract US cities, states\n",
    "print('start')\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "city_file = '/Users/macos/thunder/ner-tf/jeff_work/place_list/city.txt'\n",
    "state_file = '/Users/macos/thunder/ner-tf/jeff_work/place_list/state.txt'\n",
    "us_city = '/Users/macos/Desktop/Edison-ai/data/ner/loc/simplemaps_uscities_basicv1.6/uscities.csv'\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df = pd.read_csv(us_city)\n",
    "# df.head()\n",
    "body = (df['city'])\n",
    "states = df['state_name']\n",
    "with open(city_file, 'w') as w:\n",
    "    for city in body:\n",
    "        w.writelines(city)\n",
    "        w.writelines('\\n')\n",
    "with open(state_file, 'w') as v:\n",
    "    for state in states:\n",
    "        v.writelines(state)\n",
    "        v.writelines('\\n')\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "914\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "outfilename = '/Users/macos/thunder/ner-tf/cls_data/tel_clean.txt'\n",
    "infilename ='/Users/macos/Desktop/nc/data/train/tel.txt'\n",
    "lines_seen = set() # holds lines already seen\n",
    "outfile = open(outfilename, \"w\")\n",
    "for line in open(infilename, \"r\"):\n",
    "    if line not in lines_seen: # not a duplicate\n",
    "        outfile.write(line)\n",
    "        lines_seen.add(line)\n",
    "outfile.close()\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "start\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Extract occupations CSV data from oneTonline\n",
    "print('start')\n",
    "import pandas as pd\n",
    "\n",
    "occ_out = '/Users/macos/thunder/ner-tf/cls_data/extra/occ.txt'\n",
    "occ_file = '/Users/macos/Desktop/Edison-ai/data/ner/occupations/All_Occupations.csv'\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df = pd.read_csv(occ_file)\n",
    "# df.head()\n",
    "body = (df['Occupation'])\n",
    "with open(occ_out, 'w') as w:\n",
    "    for occ in body:\n",
    "        w.writelines(occ)\n",
    "        w.writelines('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 1250/1250 [00:00<00:00, 196753.11it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "start\n",
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## extract job_skills from google\n",
    "print('start')\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "jobs_out = '/Users/macos/thunder/ner-tf/cls_data/extra/jobs.txt'\n",
    "jobs_file = '/Users/macos/Desktop/Edison-ai/data/ner/occupations/job_skills.csv'\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df = pd.read_csv(jobs_file)\n",
    "# df.head()\n",
    "body = (df['Title'])\n",
    "info = (df['Category'])\n",
    "with open(jobs_out, 'w') as w:\n",
    "    for tit in body:\n",
    "        w.writelines(tit)\n",
    "        w.writelines('\\n')\n",
    "    for cat in tqdm(info):\n",
    "        w.writelines(cat)\n",
    "        w.writelines('\\n')\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "start\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      " 66%|██████▌   | 3276/5000 [23:22<12:15,  2.34it/s]"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## extract job_skills peopledatalabs\n",
    "print('start')\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from googletrans import Translator\n",
    "\n",
    "jobs_out = '/Users/macos/thunder/ner-tf/cls_data/extra/title_skill.txt'\n",
    "jobs_file = '/Users/macos/Desktop/Edison-ai/data/ner/occupations/pdl_related_title_dataset/2019_free_title_data.csv'\n",
    "\n",
    "\n",
    "translator = Translator()\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df = pd.read_csv(jobs_file)\n",
    "df.head()\n",
    "body = (df['title'])\n",
    "info = (df['top related titles'])\n",
    "with open(jobs_out, 'w') as w:\n",
    "        for n,tit in enumerate(tqdm(body)):\n",
    "            try:\n",
    "                trans = translator.translate(tit)\n",
    "                w.writelines(trans.text)\n",
    "                w.writelines('\\n')\n",
    "            except:\n",
    "                try:\n",
    "                     w.writelines(tit)\n",
    "                     w.writelines('\\n')\n",
    "                except:\n",
    "                    pass\n",
    "             # print(n)\n",
    "        for m,rel in enumerate(tqdm(info)):\n",
    "            try:\n",
    "                trans1 = translator.translate(rel)\n",
    "                w.writelines(trans1.text)\n",
    "                w.writelines('\\n')\n",
    "            except:\n",
    "                try:\n",
    "                    w.writelines(rel)\n",
    "                    w.writelines('\\n')\n",
    "                except:\n",
    "                    pass\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "start\n",
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## extract sf street names\n",
    "print('start')\n",
    "import pandas as pd\n",
    "name_file ='/Users/macos/Desktop/Edison-ai/data/ner/loc/sf-street-names/street-names.csv'\n",
    "nat_out = '/Users/macos/thunder/ner-tf/cls_data/extra/street_name.txt'\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df = pd.read_csv(name_file)\n",
    "df.head()\n",
    "body = (df['FullStreetName'])\n",
    "with open(nat_out, 'w') as w:\n",
    "    for occ in body:\n",
    "        w.writelines(occ)\n",
    "        w.writelines('\\n')\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 30550.53it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "start!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## extract QA\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('start!')\n",
    "qa_file = '/Users/macos/Desktop/Edison-ai/ner-tflite/qa_test/SigWeb/0327/fail_info.xls'\n",
    "# baby_file = '/Users/macos/Desktop/Edison-ai/data/ner/names/us-baby-names/StateNames.csv'\n",
    "qa_out = '/Users/macos/thunder/ner-tf/cls_data/extra/qa.txt'\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df = pd.read_excel(qa_file)\n",
    "# df.head()\n",
    "with open(qa_out, 'w') as w:\n",
    "    # body = (df['STREET'])\n",
    "    names = (df['exp'])\n",
    "    try:\n",
    "        for name in tqdm(names):\n",
    "            # print(occ)\n",
    "            w.writelines(name.split())\n",
    "            w.writelines('\\n')\n",
    "    except:\n",
    "        print('error!')\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('start!')\n",
    "baby_file = '/Users/macos/Desktop/Edison-ai/data/ner/names/us-baby-names/NationalNames.csv'\n",
    "# baby_file = '/Users/macos/Desktop/Edison-ai/data/ner/names/us-baby-names/StateNames.csv'\n",
    "baby_out = '/Users/macos/thunder/ner-tf/cls_data/extra/baby_name.txt'\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df = pd.read_csv(baby_file)\n",
    "# df.head()\n",
    "with open(baby_out, 'w') as w:\n",
    "    # body = (df['STREET'])\n",
    "    names = (df['Name'])\n",
    "    try:\n",
    "        for name in tqdm(names):\n",
    "            # print(occ)\n",
    "            w.writelines(name)\n",
    "            w.writelines('\\n')\n",
    "    except:\n",
    "        print('error!')\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## extract la street names\n",
    "print('start')\n",
    "import pandas as pd\n",
    "la_file ='/Users/macos/Desktop/Edison-ai/data/ner/loc/openaddresses-north-america-excluding-us/mexico.csv'\n",
    "la_out = '/Users/macos/thunder/ner-tf/cls_data/extra/mex_name.txt'\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df = pd.read_csv(la_file)\n",
    "# df.head()\n",
    "with open(la_out, 'w') as w:\n",
    "    body = (df['STREET'])\n",
    "    city = (df['CITY'])\n",
    "    try:\n",
    "        for occ in tqdm(body):\n",
    "            # print(occ)\n",
    "            w.writelines(occ)\n",
    "            w.writelines('\\n')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for cit in city:\n",
    "            w.writelines(cit)\n",
    "            w.writelines('\\n')\n",
    "    except:\n",
    "        pass\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "start\n",
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## extract chicago street names\n",
    "print('start')\n",
    "import pandas as pd\n",
    "ch_file ='/Users/macos/Desktop/Edison-ai/data/ner/loc/chicago-street-names/chicago-street-names.csv'\n",
    "ch_out = '/Users/macos/thunder/ner-tf/cls_data/extra/chic_name.txt'\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df = pd.read_csv(ch_file)\n",
    "df.head()\n",
    "body = (df['Full Street Name'])\n",
    "with open(ch_out, 'w') as w:\n",
    "    for occ in body:\n",
    "        occ = occ[2:]\n",
    "        w.writelines(occ)\n",
    "        w.writelines('\\n')\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "  8%|▊         | 1/13 [00:06<01:14,  6.19s/it]/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,4,5,6,7,8,9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 15%|█▌        | 2/13 [00:13<01:12,  6.60s/it]/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,5,6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 38%|███▊      | 5/13 [00:21<00:31,  3.89s/it]/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,3,4,5,7,8,9,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 54%|█████▍    | 7/13 [00:55<00:55,  9.22s/it]/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 62%|██████▏   | 8/13 [00:55<00:33,  6.62s/it]/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,5,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 69%|██████▉   | 9/13 [00:58<00:22,  5.57s/it]/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 77%|███████▋  | 10/13 [01:00<00:13,  4.58s/it]/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 92%|█████████▏| 12/13 [01:05<00:03,  3.25s/it]/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "100%|██████████| 13/13 [01:06<00:00,  5.13s/it]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "start!\n",
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## extract us ne street names\n",
    "print('start!')\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "ch_dir ='/Users/macos/Desktop/Edison-ai/data/ner/loc/openaddresses-us-northeast/'\n",
    "south_dir = '/Users/macos/Desktop/Edison-ai/data/ner/loc/openaddresses-us-south/'\n",
    "ch_out = '/Users/macos/thunder/ner-tf/cls_data/extra/us_name.txt'\n",
    "mw_dir = '/Users/macos/Desktop/Edison-ai/data/ner/loc/openaddresses-us-west/'\n",
    "\n",
    "import os\n",
    "filelist = os.listdir(mw_dir)\n",
    "with open(ch_out, 'w') as w:\n",
    "    for i in tqdm(filelist):\n",
    "        if i.endswith(\".csv\"):  # You could also add \"and i.startswith('f'\n",
    "            df = pd.read_csv(mw_dir + i)\n",
    "            body = (df['STREET'])\n",
    "            city = (df['CITY'])\n",
    "            try:\n",
    "                for occ in body:\n",
    "                    # print(occ)\n",
    "                    w.writelines(occ)\n",
    "                    w.writelines('\\n')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                for cit in city:\n",
    "                    w.writelines(cit)\n",
    "                    w.writelines('\\n')\n",
    "            except:\n",
    "                pass\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "##split by 2 lines\n",
    "hold_file = '/Users/macos/thunder/ner-tf/jeff_work/process_data/hold.txt'\n",
    "output_file = '/Users/macos/thunder/ner-tf/cls_data/clean.txt'\n",
    "\n",
    "with open(hold_file, \"r\") as r, open(output_file, \"w\") as w:\n",
    "    z = r.readlines()\n",
    "    twol = range(0,len(z),2)\n",
    "    for num, line in enumerate(z):\n",
    "        if num in twol:\n",
    "            loc = ' '.join(z[num:num+2])\n",
    "            w.writelines(loc)\n",
    "            w.writelines('\\n')\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 173965/173965 [00:00<00:00, 1857057.66it/s]\n",
      "100%|██████████| 189382/189382 [00:00<00:00, 1804740.11it/s]\n",
      "100%|██████████| 173965/173965 [19:26<00:00, 149.17it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "start!\n",
      "time to check!\n",
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('start!')\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Remove names from ORG\n",
    "name_list = ['bob', 'bob lim', 'jeff']\n",
    "lines = \"\"\"CLAWI - Mundo Gaturro\n",
    "CityOdds\n",
    "BettingVille\n",
    "Ototespit . com\n",
    "iLogistix\n",
    "MotorExchange\n",
    "Market Research\n",
    "Fingerworks\n",
    "Ladenburg Thalmann\n",
    "Encryptosoft\n",
    "PolySpot Enterprise Search\n",
    "bob works\n",
    "bob\n",
    "TrenMedia\n",
    "jeffur\n",
    "JadeTrack\"\"\"\n",
    "name_file = '/Users/macos/Desktop/nc/data/train/name.txt'\n",
    "org_file  = '/Users/macos/Desktop/nc/data/train/org.txt'\n",
    "new_org = '/Users/macos/thunder/ner-tf/jeff_work/new_org.txt'\n",
    "\n",
    "body = []\n",
    "name_list = []\n",
    "with open(name_file, 'r') as r, open(org_file, 'r') as s, open(new_org, 'w') as w:\n",
    "    name_body = r.readlines()\n",
    "    for name in tqdm(name_body):\n",
    "        name_list.append(name)\n",
    "        \n",
    "    org_body = s.readlines()\n",
    "    for org in tqdm(org_body):\n",
    "        body.append(org)\n",
    "    # body = org_body.split('\\n')\n",
    "    print('time to check!')\n",
    "# body = lines.split('\\n')\n",
    "# [i for i in name_list if i in body]\n",
    "# print(i)\n",
    "    for i in tqdm(name_list):\n",
    "        if i in body:\n",
    "            body.remove(i)\n",
    "            # print(i)\n",
    "        # else:\n",
    "        #     w.writelines(i)\n",
    "        #     w.writelines('\\n')\n",
    "    for ele in body:\n",
    "        w.writelines(ele)\n",
    "        # w.writelines('\\n')\n",
    "print('ok')\n",
    "# for line in lines:\n",
    "#     if name_list in :\n",
    "#         print(line)\n",
    "#     else:\n",
    "#         print('nope!')\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 29830/29830 [00:00<00:00, 864234.47it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "input_file = \"/Users/macos/thunder/ner-tf/jeff_work/process_data/hold.txt\"\n",
    "body = []\n",
    "with open(input_file, \"r\") as fp:\n",
    "    source = fp.readlines()\n",
    "    for line in source:\n",
    "        newline = line.replace(',', '')\n",
    "        body.append(newline)\n",
    "    \n",
    "output_file = \"/Users/macos/thunder/ner-tf/cls_data/clean.txt\"\n",
    "with open(output_file, \"w\") as fp:\n",
    "    for line in tqdm(body):\n",
    "        fp.write(line)\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 18395/18395 [00:03<00:00, 5916.92it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "start\n",
      "ok\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## BEST IN REMOVING DUPLICATES, WHITE SPACE\n",
    "## \n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "print('start')\n",
    "input_file = \"/Users/macos/thunder/ner-tf/jeff_work/process_data/hold.txt\"\n",
    "# input_File = \"/Users/macos/thunder/ner-tf/cls_data/extra/company_us.txt\"\n",
    "with open(input_file, \"r\") as fp:\n",
    "    source = fp.readlines()\n",
    "    for i in range(2):   \n",
    "        data = [ (random.random(), line) for line in source ]\n",
    "        data.sort() \n",
    "    #shuffle lines\n",
    "    \n",
    "    new_lines = []\n",
    "    for _,line in tqdm(data):\n",
    "        #- Strip white spaces\n",
    "        line = line.strip()\n",
    "        if line not in new_lines:\n",
    "            new_lines.append(line)\n",
    "\n",
    "output_file = \"/Users/macos/thunder/ner-tf/cls_data/clean.txt\"\n",
    "with open(output_file, \"w\") as fp:\n",
    "    fp.write(\"\\n\".join(new_lines))\n",
    "print('ok')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}